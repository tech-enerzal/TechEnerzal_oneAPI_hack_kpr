{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset overview\n",
    "\n",
    "```\n",
    "{\n",
    "    \"sections\": [\n",
    "    {\n",
    "      \"metadata\": {\n",
    "       \"section_name\": \"Recruitment Policy\",\n",
    "       \"keywords\": [\"manpower requisition\", \"recruitment process\", \"interview panel\", \"medical examination\"],\n",
    "       \"page_number\": [9, 11],\n",
    "       \"category\": \"Recruitment\",\n",
    "       \"sub_category\": \"Recruitment Process\",\n",
    "       \"difficulty_level\": \"Intermediate\",\n",
    "       \"date_updated\": \"2024-09-10\",\n",
    "       \"qa_pairs\": [\n",
    "         {\n",
    "         \"input\": \"What is the process for raising a manpower requisition at IIMA?\",\n",
    "         \"response\": \"Manpower requisition at IIMA is initiated by the concerned department by filling a Manpower Requisition Form (MRF). The MRF must include the pay level, tenure of employment, and a brief job description. The requisition is approved by the Director before recruitment begins.\",\n",
    "         \"source\": \"HR Policy Manual, Page 9\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"What documents are required during the joining process at IIMA?\",\n",
    "         \"response\": \"During the joining process, candidates are required to submit documents including mark sheets from 10th to the last qualified exam, passing certificates, birth certificate, address proof, relieving letter from the last employer, medical fitness certificate, and identification proof such as Aadhar card, PAN card, or passport.\",\n",
    "         \"source\": \"HR Policy Manual, Page 11\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"Who constitutes the interview panel for positions at IIMA?\",\n",
    "         \"response\": \"For Manager and above positions, the interview panel includes members such as the OEDC member, Dean, Chief Administrative Officer, Head of Department, and the Associate Vice President - HR. Additional experts may be included if required.\",\n",
    "         \"source\": \"HR Policy Manual, Page 10\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"What are the criteria for selecting a candidate at IIMA?\",\n",
    "         \"response\": \"Candidates are selected based on personal interviews, skill tests, group discussions, and reference checks. The final selection is subject to a medical examination.\",\n",
    "         \"source\": \"HR Policy Manual, Page 11\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"What is the role of the HR department in recruitment at IIMA?\",\n",
    "         \"response\": \"The HR department is responsible for processing applications, scheduling interviews, conducting background checks, and negotiating salaries during the recruitment process.\",\n",
    "         \"source\": \"HR Policy Manual, Page 9\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"What is the medical examination requirement during recruitment?\",\n",
    "         \"response\": \"All candidates must undergo a medical examination either at the IIMA facility or through a recognized civil hospital. The doctor may request additional tests if necessary.\",\n",
    "         \"source\": \"HR Policy Manual, Page 11\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"What steps are included in IIMA's joining process?\",\n",
    "         \"response\": \"The joining process includes the submission of the Candidate’s Statement & Declaration, document verification, submission of a joining report, and the issuing of a Joining Memorandum.\",\n",
    "         \"source\": \"HR Policy Manual, Page 11\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"What kind of advertisement process is followed for recruitment at IIMA?\",\n",
    "         \"response\": \"IIMA releases recruitment advertisements in newspapers, and feedback is gathered from the relevant department heads before publication.\",\n",
    "         \"source\": \"HR Policy Manual, Page 9\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"How are applications processed during recruitment?\",\n",
    "         \"response\": \"The HR department is responsible for segregating resumes, compiling the details of applicants, and forwarding them to the concerned department for shortlisting.\",\n",
    "         \"source\": \"HR Policy Manual, Page 9\"\n",
    "         },\n",
    "         {\n",
    "         \"input\": \"What kind of travel reimbursement is provided to candidates during recruitment?\",\n",
    "         \"response\": \"For Manager and above positions, economy air travel fare is reimbursed. For Level 6 to Level 9 positions, AC 3-Tier train fare is reimbursed, and Sleeper Class train fare is reimbursed for lower levels.\",\n",
    "         \"source\": \"HR Policy Manual, Page 10\"\n",
    "         }\n",
    "        ]\n",
    "      },\n",
    "      \"description\": \"The recruitment process at IIMA starts with the Manpower Requisition Form (MRF). This form is filled by the concerned department, detailing the pay level, tenure of employment, job description, and justification for the position. The approval process requires the MRF to be signed off by the department chairperson and then forwarded to the HR department. The HR Manager and the Associate Vice President-HR discuss the proposal with the department head and the Director, who give the final approval. Once approved, the job advertisement is prepared and released in selected newspapers. The advertisement copy may also be reviewed by the Head of Department for feedback before publication. The HR department segregates resumes based on eligibility and sends them to the concerned department for shortlisting. After shortlisting, the interview panel is constituted. For Manager and above positions, the interview panel includes the OEDC member, Dean, Chief Administrative Officer, Head of Department, Associate Vice President-HR, and any expert nominated by the Director. For positions below Manager level, the panel consists of the SEDC member, Head of Department, Associate VP-HR, and a nominated person. The interview process may include personal interviews, skill tests, group discussions, debates, or quizzes. Candidates are informed via email, followed by a formal letter for interview scheduling. After the interview, feedback from panel members is documented, and the HR department assists with salary negotiations and collects feedback from references if necessary. Travel reimbursement for Manager and above positions covers economy class airfare. For candidates applying to positions from Level 6 to Level 9, AC 3-tier train fare is reimbursed, while those below Level 6 are reimbursed sleeper class train fare. After selection, candidates must undergo a medical check-up or submit a fitness certificate. The joining procedure involves collecting primary details through a Candidate’s Statement and Declaration form and verifying documents such as mark sheets, certificates, birth certificate, address proof, relieving letter, latest salary slip, medical certificate, and identity proof. The final steps include the issuance of a joining report and an identity card.\"\n",
    "  \n",
    "    },\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langchain-faiss (from versions: none)\n",
      "ERROR: No matching distribution found for langchain-faiss\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-faiss faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_29396\\3545694070.py:17: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\priya\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.schema import Document\n",
    "\n",
    "# FAISS imports\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def split_into_batches(docs, batch_size):\n",
    "    for i in range(0, len(docs), batch_size):\n",
    "        yield docs[i:i + batch_size]\n",
    "\n",
    "\n",
    "def load_and_process_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    Full_HR = []\n",
    "    QA_HR = []\n",
    "\n",
    "    # Iterate over each section in the JSON data\n",
    "    for section in data.get('sections', []):\n",
    "        metadata = section.get('metadata', {})\n",
    "        description = section.get('description', '')\n",
    "    \n",
    "        # Extract metadata fields\n",
    "        section_name = metadata.get('section_name', '')\n",
    "        keywords = metadata.get('keywords', [])\n",
    "        page_number = metadata.get('page_number', [])\n",
    "        category = metadata.get('category', '')\n",
    "        sub_category = metadata.get('sub_category', '')\n",
    "        difficulty_level = metadata.get('difficulty_level', '')\n",
    "        date_updated = metadata.get('date_updated', '')\n",
    "        qa_pairs = metadata.get('qa_pairs', [])\n",
    "    \n",
    "        # Create a Document for the section description\n",
    "        doc_metadata = {\n",
    "            'section_name': section_name,\n",
    "            'keywords': ', '.join(keywords) if isinstance(keywords, list) else keywords,\n",
    "            'page_number': ', '.join(map(str, page_number)) if isinstance(page_number, list) else page_number,\n",
    "            'category': category,\n",
    "            'sub_category': sub_category,\n",
    "            'difficulty_level': difficulty_level,\n",
    "            'date_updated': date_updated,\n",
    "        }\n",
    "    \n",
    "        description_doc = Document(\n",
    "            page_content=description,\n",
    "            metadata=doc_metadata\n",
    "        )\n",
    "        Full_HR.append(description_doc)\n",
    "    \n",
    "        # Create Documents for each QA pair\n",
    "        for index, qa in enumerate(qa_pairs):\n",
    "            question = qa.get('input', '')\n",
    "            answer = qa.get('response', '')\n",
    "            source = qa.get('source', '')\n",
    "            qa_content = f\"Question: {question}\\nAnswer: {answer}\\nSource: {source}\"\n",
    "            qa_metadata = {\n",
    "                'section_name': section_name,\n",
    "                'keywords': ', '.join(keywords) if isinstance(keywords, list) else keywords,\n",
    "                'page_number': ', '.join(map(str, page_number)) if isinstance(page_number, list) else page_number,\n",
    "                'category': category,\n",
    "                'sub_category': sub_category,\n",
    "                'difficulty_level': difficulty_level,\n",
    "                'date_updated': date_updated,\n",
    "                'source': source\n",
    "            }\n",
    "    \n",
    "            QA_doc = Document(\n",
    "                page_content=qa_content,\n",
    "                metadata=qa_metadata\n",
    "            )\n",
    "            QA_HR.append(QA_doc)\n",
    "\n",
    "    # Create FAISS vector stores\n",
    "    faiss_full_hr = FAISS.from_documents(Full_HR, embedding_function)\n",
    "    faiss_qa_hr = FAISS.from_documents(QA_HR, embedding_function)\n",
    "\n",
    "    # Optionally, save the FAISS indexes for later use\n",
    "    faiss_full_hr.save_local(\"HR/Vector/Full_HR\")\n",
    "    faiss_qa_hr.save_local(\"HR/Vector/QA_HR\")\n",
    "\n",
    "    return faiss_full_hr, faiss_qa_hr\n",
    "\n",
    "\n",
    "# Path to your JSON file\n",
    "file_path = 'HR/hr-policy-final.json'\n",
    "db_Full_HR, db_QA_HR = load_and_process_data(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_27068\\919284486.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\priya\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the FAISS indexes\n",
    "faiss_full_hr = FAISS.load_local(\"HR/Vector/Full_HR\", embedding_function,allow_dangerous_deserialization=True)\n",
    "faiss_qa_hr = FAISS.load_local(\"HR/Vector/QA_HR\", embedding_function,allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = \"What is the process for recruitment at IIMA?\"\n",
    "\n",
    "# Perform similarity search on the QA vector store\n",
    "docs = faiss_full_hr.similarity_search(query, k=20)\n",
    "\n",
    "# Display the results\n",
    "for doc in docs:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
